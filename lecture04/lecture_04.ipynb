{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 04 -- Starting a data project\n",
    "* Learning the business case\n",
    "* Define a MVP\n",
    "* Data collection\n",
    "* Data sanity checks, cleansing\n",
    "* Explorative analysis\n",
    "* Preparing the data for a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of lessons from lecture_02 on employee attrition risk model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example project -- Employee attrition model\n",
    "* \"I want to know why are my employees leaving and what can I do to mitigate that?\n",
    "* What kind of data we would be exploring?\n",
    "* Where does this data coming from?\n",
    "* What type of problem is this? Classification? Regression?\n",
    "* How can we structure easily attainable validation proof-of-concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://community.ibm.com/community/user/datascience/blogs/archive-user/2016/10/31/unlock-the-secrets-to-employee-retention-with-predictive-analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The costs of hiring/losing an employee\n",
    "\n",
    "# The cost of hiring a new employee, including the advertising, interviewing, screening, and hiring.\n",
    "# On-boarding a new worker, including training and management time.\n",
    "# Lost productivity, because it may take a new employee 1-2 years to reach the productivity of an existing one.\n",
    "# Lost engagement as other employees who see high turnover tend to disengage and lose productivity.\n",
    "# Training costs, which can add up to as 10-20 percent of an employee's salary or more in training for the first several years.\n",
    "# Cultural impact, as whenever someone leaves other employees will ask \"Why?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the source of the data\n",
    "\n",
    "# ERP (enterprise resource planning)\n",
    "# What/who manages the data\n",
    "# Governed manually or by some process?\n",
    "# Mix of multiple systems, legacy solutions?\n",
    "# Shit in, shit out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification problem\n",
    "\n",
    "# Employee terminated = boolean label\n",
    "# Estimation of various factors\n",
    "# Prediction of attrition with some confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple proof-of-concept\n",
    "\n",
    "# Linear model to estimate potential factors\n",
    "# Which factors are actionable or make sense in the business context?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start exploring the data in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks\n",
    "\n",
    "![sci_paper.png](pics/sci_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/\n",
    "* Interactive, original idea based on Mathematica's Notebooks\n",
    "* Probably best environment for playing around\n",
    "* Very weak for version control and some serious collaboration\n",
    "* For anything more than a prototype or lecture purpose, switch to proper coding environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyterlab.png](pics/jupyterlab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Demo\n",
    "Play with [demo-notebook.ipynb](demo-notebook.ipynb)\n",
    "* Are you able to open the notebook?\n",
    "* Are you able to run/edit some cell and see the response?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives\n",
    "* Google Colab (https://colab.research.google.com/)\n",
    "* Deepnote (https://deepnote.com/dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import core libraries and the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pandas is THE python library when dealing with tabular data\n",
    "import os\n",
    "# standard set of OS-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import <module> -- whole module\n",
    "# from <module> import <objects> -- separate objects, can be referenced without module name\n",
    "# import <module> as <alias> -- aliasing for simplicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir()\n",
    "# basicaly \"ls\" bash command of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the content of the \"data\" folder\n",
    "os.listdir(\"data/\")\n",
    "# This is computer-specific!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's what we want to import\n",
    "#dataFile = \"data/WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
    "# insert your path to the data\n",
    "dataFile = \"data/\"+os.listdir(\"data\")[0]\n",
    "empData = pd.read_csv(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(empData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if we imported the file correctly, displaying first 100 rows\n",
    "empData.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from other places aka detour to APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent routes to getting data are:\n",
    "* DBs -- usually, you'll be on the receiving end of analytical DBs. Basic SQL is pretty good skill to have.\n",
    "* Cloud storage -- AWS S3 and others. Again, ultra basic skill with cloud services goes a long way in your data science or ML career.\n",
    "* APIs -- REST or GraphQL. A standard how services/apps communicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples to elaborate:\n",
    "* https://www.postman.com/api-evangelist/workspace/strava/request/35240-0bdb8a2d-f758-4d0f-9fb2-befe9b7d81c5?ctx=code\n",
    "* https://developers.strava.com/docs/getting-started/#curl\n",
    "* https://www.strava.com/settings/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"httpswww.strava.com/api/v3/athlete/\n",
    "\n",
    "payload={}\n",
    "headers = {\n",
    "  'Authorization': 'Bearer 3a9ad2f90646eda08cefe5c2daf2a7b87a5468dd'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint #1\n",
    "* [ ] I imported the pandas and os libraries\n",
    "* [ ] I downloaded the data into a folder to which I can navigate from Jupyter\n",
    "* [ ] I imported the data as a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's dig deeper into the basics of working with pandas dataframe (df ~ table, np.array ~ matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing the data by columns\n",
    "# dataFrame[column_name] or dataFrame[list_of_columns]\n",
    "empData['Attrition'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing the data, labels-based\n",
    "# dataFrame.loc[row_names, columns_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's select first 10 rows and first column\n",
    "empData.loc[1:10, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now first 2 columns\n",
    "empData.loc[1:10, 'Age', 'Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll have to put them into a list of fields\n",
    "empData.loc[1:10, ['Age', 'Attrition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different kind of slicing, through integer-based position\n",
    "empData.iloc[1:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strange, huh? What about this?\n",
    "empData.iloc[1:10,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last slice\n",
    "empData.iloc[1:10,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing starts from 0 of course!\n",
    "# not-inclusive, so [1:3] kind-of means [2,3,4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by maps (condition-based slicing)\n",
    "# let's create a map for all terminated employees\n",
    "terms = (empData['Attrition'] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.loc[terms,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can slice it by this\n",
    "(empData.loc[terms,:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining conditions, let's say terminated employees in Sales\n",
    "termsSales = ((terms) & (empData['Department'] == 'Sales'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.loc[termsSales,:].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns to a dataFrame\n",
    "empData['myNewColumn'] = 'You look nice today!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D data with axis!\n",
    "type(empData['Department'] == 'Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(empData['Department'] == 'Sales').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on some condition\n",
    "empData['worksForSales'] = (empData['Department'] == 'Sales').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint #2\n",
    "* [ ] I can select three arbitrary columns from the data\n",
    "* [ ] I can add a new field which will label frequent travelers with medical background\n",
    "* [ ] I can return the data into the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData['frequentMedicals'] = ((empData['BusinessTravel'] == 'Travel_Frequently') & \n",
    "                              (empData['EducationField'] == 'Medical')).values\n",
    "empData = empData.iloc[:,0:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Profiling (get some sense of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the data\n",
    "empData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes\n",
    "empData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get header\n",
    "empData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic description\n",
    "empData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupings\n",
    "# let's create a sensible subselect first\n",
    "empData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about monthly income by age?\n",
    "empData.loc[:,['Age', 'MonthlyIncome', 'JobSatisfaction']].groupby(['Age']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with NaNs, nulls or missing values\n",
    "empData['Age'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there any?\n",
    "empData['Age'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about detecting nulls in any column?\n",
    "empData.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about detecting nulls in any column?\n",
    "empData.isnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaNs\n",
    "empData.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly from df/series\n",
    "empData['Age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic linechart\n",
    "empData.loc[:,['Age', 'MonthlyIncome']].groupby(['Age']).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring more interactivity with Plotly\n",
    "# \"Cufflinks binds Plotly directly to pandas dataframes.\"\n",
    "import cufflinks as cf\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.loc[:,['MonthlyIncome']].iplot(kind='histogram', bins = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empData.loc[:,['Age', 'MonthlyIncome']].groupby(['Age']).mean().iplot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "import seaborn as sn\n",
    "corrMatrix = empData.corr()\n",
    "plt.figure(figsize=(25, 20))\n",
    "sn.heatmap(corrMatrix, annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas-profiling library https://github.com/pandas-profiling/pandas-profiling\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(empData, title=\"Employee Data Profiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"jak_to_dopadlo.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/great_expectations_integration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some exploration of potential factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to estimate average and standard deviation by normal distribution\n",
    "(mu, sigma) = norm.fit(empData.loc[empData['Attrition'] == 'Yes', 'Age'])\n",
    "print(\n",
    "    'Ex-exmployees: average age = {:.1f} years old and standard deviation = {:.1f}'.format(mu, sigma))\n",
    "(mu, sigma) = norm.fit(empData.loc[empData['Attrition'] == 'No', 'Age'])\n",
    "print(\n",
    "    'Current exmployees: average age = {:.1f} years old and standard deviation = {:.1f}'.format(mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, let's do the same \n",
    "x1 = empData.loc[empData['Attrition'] == 'No', 'Age']\n",
    "x2 = empData.loc[empData['Attrition'] == 'Yes', 'Age']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(title='Age Distribution in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[15, 60], dtick=5))\n",
    "# Plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like an interesting variable to explore, let's try to visualise that\n",
    "empData.groupby(['OverTime','Attrition']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empDataOverTime = pd.DataFrame(columns=[\"OverTime\", \"% of Leavers\"])\n",
    "i=0\n",
    "for field in list(empData['OverTime'].unique()):\n",
    "    ratio = empData[(empData['OverTime']==field)&(empData['Attrition']==\"Yes\")].shape[0] / empData[empData['OverTime']==field].shape[0]\n",
    "    empDataOverTime.loc[i] = (field, ratio*100)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empDataOverTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empDataOverTime.groupby('OverTime').sum().iplot(kind='bar', title = 'Leavers by OverTime (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "* [ ] What other factor(s) could be potentially significant?\n",
    "* [ ] Import scikit-learn package\n",
    "* [ ] Prepare the data for a simple linear model of one continuous response with and without quadratic term\n",
    "* [ ] Compare the models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
